{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71dc5a4",
   "metadata": {},
   "source": [
    "# Experimenting if eliminating class imbalance can increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c855cb",
   "metadata": {},
   "source": [
    "## Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4989f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc81625d",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_data = pd.read_csv('heart_disease_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37679069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca59b4",
   "metadata": {},
   "source": [
    "## Data Exploration and Elimination of Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6476fc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f196b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_negative = heart_disease_data[heart_disease_data['target'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392cc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_positive = heart_disease_data[heart_disease_data['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3787e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_positive_sample = heart_disease_positive.sample(heart_disease_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0e84ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_positive_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05b784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([heart_disease_positive_sample, heart_disease_negative], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a631194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "907abca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "65    35    0   0       138   183    0        1      182      0      1.4   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "152   64    1   3       170   227    0        0      155      0      0.6   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "42    45    1   0       104   208    0        0      148      1      3.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "65       2   0     2       1  \n",
       "63       1   0     1       1  \n",
       "152      1   0     3       1  \n",
       "124      2   0     2       1  \n",
       "42       1   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[276 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7ad4e",
   "metadata": {},
   "source": [
    "## Splitting the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2516fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.drop(columns=['target'])\n",
    "y = merged_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02335a92",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c493126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bb561",
   "metadata": {},
   "source": [
    "## Scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62ae92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35f5f3",
   "metadata": {},
   "source": [
    "## Building the models followed by model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43ac789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    {\n",
    "        'name': 'Logistic Regression',\n",
    "        'classifier': LogisticRegression(max_iter=2000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'solver': ['liblinear', 'lbfgs']\n",
    "        },\n",
    "        'train_data': 'X_train_scaled'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Decision Tree',\n",
    "        'classifier': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [None, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'train_data': 'X_train'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Support Vector Machine',\n",
    "        'classifier': SVC(max_iter=2000),\n",
    "        'params': {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        },\n",
    "        'train_data': 'X_train_scaled'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'classifier': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 5, 10]\n",
    "        },\n",
    "        'train_data': 'X_train'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Gaussian Naive Bayes',\n",
    "        'classifier': GaussianNB(),\n",
    "        'params': {},\n",
    "        'train_data': 'X_train'\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "909e84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Classifier', 'Best Parameters', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65be9750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_8760\\4204547685.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_8760\\4204547685.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\.android\\trial\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_8760\\4204547685.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_8760\\4204547685.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "C:\\Users\\anupa\\AppData\\Local\\Temp\\ipykernel_8760\\4204547685.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    if classifier['train_data'] == 'X_train':\n",
    "        X_train_data = X_train\n",
    "    elif classifier['train_data'] == 'X_train_scaled':\n",
    "        X_train_data = X_train_scaled\n",
    "    else:\n",
    "        raise ValueError(\"Invalid train_data value. Must be 'X_train' or 'X_train_scaled'.\")\n",
    "    \n",
    "    grid_search = GridSearchCV(classifier['classifier'], classifier['params'], cv=5)\n",
    "    grid_search.fit(X_train_data, y_train)\n",
    "    best_classifier = grid_search.best_estimator_\n",
    "    if classifier['train_data'] == 'X_train':\n",
    "        y_pred = best_classifier.predict(X_test)\n",
    "    elif classifier['train_data'] == 'X_train_scaled':\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        y_pred = best_classifier.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    results_df = results_df.append({\n",
    "        'Classifier': classifier['name'],\n",
    "        'Best Parameters': grid_search.best_params_,\n",
    "        'Accuracy': accuracy\n",
    "    }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741462f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.732143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 10.0, 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier                               Best Parameters  \\\n",
       "0     Logistic Regression                 {'C': 0.1, 'solver': 'lbfgs'}   \n",
       "1           Decision Tree  {'max_depth': None, 'min_samples_split': 10}   \n",
       "2  Support Vector Machine               {'C': 10.0, 'kernel': 'linear'}   \n",
       "3           Random Forest         {'max_depth': 5, 'n_estimators': 100}   \n",
       "4    Gaussian Naive Bayes                                            {}   \n",
       "\n",
       "   Accuracy  \n",
       "0  0.857143  \n",
       "1  0.732143  \n",
       "2  0.857143  \n",
       "3  0.803571  \n",
       "4  0.785714  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86f0a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 10.0, 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 10}</td>\n",
       "      <td>0.732143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier                               Best Parameters  \\\n",
       "0     Logistic Regression                 {'C': 0.1, 'solver': 'lbfgs'}   \n",
       "2  Support Vector Machine               {'C': 10.0, 'kernel': 'linear'}   \n",
       "3           Random Forest         {'max_depth': 5, 'n_estimators': 100}   \n",
       "4    Gaussian Naive Bayes                                            {}   \n",
       "1           Decision Tree  {'max_depth': None, 'min_samples_split': 10}   \n",
       "\n",
       "   Accuracy  \n",
       "0  0.857143  \n",
       "2  0.857143  \n",
       "3  0.803571  \n",
       "4  0.785714  \n",
       "1  0.732143  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05a3a3",
   "metadata": {},
   "source": [
    "Booyah! Eliminating class imbalance did the trick...increased the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6943573",
   "metadata": {},
   "source": [
    "Logistic Regression and SVC have the same accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2da04b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, kernel='linear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC(C=10, kernel='linear')\n",
    "model_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18f6be6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545454545454545"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model_svc.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c263b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=0.1, solver='lbfgs')\n",
    "model_lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbdd57d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318181818181818"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = model_lr.predict(X_train_scaled)\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b762b8",
   "metadata": {},
   "source": [
    "SVC model seems to have lesser overfitting than Logistic Regression. I'll go with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b395e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
